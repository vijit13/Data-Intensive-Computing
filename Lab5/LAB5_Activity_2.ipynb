{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('abigo', 0), ('abactus', 0)]\n"
     ]
    }
   ],
   "source": [
    "lemmas=dict()\n",
    "lemma = open('new_lemmatizer.csv')\n",
    "\n",
    "for line in lemma:\n",
    "    val=list()\n",
    "    roots = line.split(',')\n",
    "    end=len(roots)\n",
    "    if roots.count('\\n') > 0:\n",
    "        roots.remove('\\n')\n",
    "    #if roots.count('') > 0:\n",
    "    #    end = roots.index('')\n",
    "    #val.clear()\n",
    "    i=0;\n",
    "    for r in roots:\n",
    "        i=i+1\n",
    "        if r != '' and i > 1:\n",
    "            val.append((r,0))\n",
    "    lemmas[roots[0]]=val#roots[1:end]\n",
    "print(lemmas['abactum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Please setup the variable as desired\n",
    "\n",
    "\n",
    "input_files_loc='input_folder'\n",
    "output_files_loc='output_folder'\n",
    "n_gram=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab1.txtinput_folder\n",
      "====>2\n",
      "ambrose.apologia_david_altera.tessinput_folder\n",
      "====>2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import time;\n",
    "\n",
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "\n",
    "dummy=sc.emptyRDD()\n",
    "txtFile=None\n",
    "\n",
    "collect=list()\n",
    "\n",
    "def do_word_co_occurence(n_gram):\n",
    "    def do_bi_gram(x):\n",
    "        init = x.split('> ')\n",
    "        if len(init) == 2:\n",
    "            a=init[1]\n",
    "            init[0]=init[0]+'>'\n",
    "            a=a.lower().replace('?','')\\\n",
    "                .replace(',','').replace('.','')\\\n",
    "                .replace('j','v').replace('i','u')\n",
    "            words = a.split(' ')\n",
    "            app = []\n",
    "            words.sort()\n",
    "            for word in words:\n",
    "                if word in lemmas:\n",
    "                    words.remove(word)\n",
    "                    app=app+lemmas[word]\n",
    "            words=words+app\n",
    "            #print(words)\n",
    "            for i in range(0,len(words)):\n",
    "                for j in range(0,len(words)):\n",
    "                    if j > i and not (isinstance(words[i],tuple) and isinstance(words[j],tuple)):\n",
    "                        if isinstance(words[i],tuple):\n",
    "                            yield ((words[i][0],words[j]),init[0])\n",
    "                        elif isinstance(words[j],tuple):\n",
    "                            yield ((words[i],words[j][0]),init[0])\n",
    "                        else:\n",
    "                            yield ((words[i],words[j]),init[0])\n",
    "\n",
    "\n",
    "    def do_tri_gram(x):\n",
    "        init = x.split('> ')\n",
    "        if len(init) == 2:\n",
    "            a=init[1]\n",
    "            init[0]=init[0]+'>'\n",
    "            a=a.lower().replace('?','')\\\n",
    "                .replace(',','').replace('.','')\\\n",
    "                .replace('j','v').replace('i','u')\n",
    "            words = a.split(' ')\n",
    "            app = []\n",
    "            words.sort()\n",
    "            for word in words:\n",
    "                if word in lemmas:\n",
    "                    words.remove(word)\n",
    "                    app=app+lemmas[word]\n",
    "            words=words+app\n",
    "            for i in range(0,len(words)):\n",
    "                for j in range(i+1,len(words)):\n",
    "                    for k in range(j+1,len(words)):\n",
    "                        \n",
    "                        # if all of the words for trigram are not tuple there will be no else\n",
    "                        if not (isinstance(words[i],tuple) and isinstance(words[j],tuple) and isinstance(words[k],tuple)):\n",
    "                            \n",
    "                            #first tuple\n",
    "                            if isinstance(words[i],tuple) and not isinstance(words[j],tuple) and not isinstance(words[k],tuple):\n",
    "                                yield ((words[i][0],words[j],words[k]),init[0])\n",
    "                            \n",
    "                            #second tuple\n",
    "                            elif isinstance(words[j],tuple) and not isinstance(words[i],tuple) and not isinstance(words[k],tuple):\n",
    "                                yield ((words[i],words[j][0],words[k]),init[0])\n",
    "                            \n",
    "                            #third tuple\n",
    "                            elif isinstance(words[k],tuple) and not isinstance(words[i],tuple) and not isinstance(words[j],tuple):\n",
    "                                yield ((words[i],words[j],words[k][0]),init[0])\n",
    "                            \n",
    "                            else:\n",
    "                                #check no two tuple\n",
    "                                if not (isinstance(words[i],tuple) or isinstance(words[j],tuple))\\\n",
    "                                and not (isinstance(words[j],tuple) or isinstance(words[k],tuple))\\\n",
    "                                and not (isinstance(words[i],tuple) or isinstance(words[k],tuple)):\n",
    "                                    yield ((words[i],words[j],words[k]),init[0])\n",
    "    \n",
    "    \n",
    "    if n_gram == 2:\n",
    "        print('====>2')\n",
    "        return txtFile.flatMap(do_bi_gram).reduceByKey(add)\n",
    "    if n_gram == 3:\n",
    "        print('====>3')\n",
    "        return txtFile.flatMap(do_tri_gram).reduceByKey(add)\n",
    "\n",
    "#collect=list()\n",
    "for file in os.listdir(input_files_loc):\n",
    "    print(file+input_files_loc)\n",
    "    txtFile=sc.textFile(os.path.join(os.path.join(os.getcwd(),input_files_loc),file))\n",
    "    collect.append(do_word_co_occurence(n_gram))\n",
    "#do_word_co_occurence(n_gram)\n",
    "print(len(collect))\n",
    "counts=sc.union(collect).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started execution at Sat May 13 23:32:00 2017\n",
      "ended execution at Sat May 13 23:32:30 2017\n"
     ]
    }
   ],
   "source": [
    "lst=counts.saveAsTextFile(output_files_loc)\n",
    "\n",
    "\n",
    "print(\"started execution at \"+localtime)\n",
    "print(\"ended execution at \"+time.asctime( time.localtime(time.time()) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cnt=0;\n",
    "#outputFile = open('ab_out_tri',mode='a')\n",
    "#for a in lst:\n",
    "#    outputFile.write(str(a)+'\\n')\n",
    "#outputFile.close()\n",
    "#for file in os.listdir(input_files_loc):\n",
    "#    for line in open(os.path.join(os.path.join(os.getcwd(),input_files_loc),file)):\n",
    "#        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=os.listdir(output_files_loc)\n",
    "cnt=0\n",
    "cnt1=0\n",
    "cnt2=0\n",
    "for a in f:\n",
    "    if a.startswith('p'):\n",
    "        for line in open(os.path.join(os.path.join(os.getcwd(),output_files_loc),a)):\n",
    "            #if '<l' in line:\n",
    "            cnt=cnt+1\n",
    "            if '<ambrose. ap_david_altera. 2>' in line:\n",
    "                cnt1=cnt1+1\n",
    "            if '<ambrose. ap_david_altera. 3>' in line:\n",
    "                cnt2=cnt2+1\n",
    "print(cnt)\n",
    "print(cnt1)\n",
    "print(cnt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0xb3cf508c>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
